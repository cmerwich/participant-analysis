{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sys import exit, stderr\n",
    "from collections import defaultdict, Counter\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "from operator import itemgetter, attrgetter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tf.app import use\n",
    "from tf.fabric import Fabric\n",
    "from utils import converse_pgn, suffix_dict\n",
    "\n",
    "\n",
    "A = use(\n",
    "    'bhsa', version='2017',\n",
    "    mod=(\n",
    "        'cmerwich/participant-analysis/coreference/tf,'\n",
    "        'cmerwich/bh-reference-system/tf'\n",
    "    ), \n",
    "    hoist=globals(),\n",
    "    silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueData:\n",
    "    def __init__(self, quintuple):\n",
    "        self.ct = quintuple[0]\n",
    "        self.seqNum = int(quintuple[1])\n",
    "        self.isSuffix = quintuple[3] == 's'\n",
    "        self.wordPart = quintuple[4]\n",
    "        if quintuple[2] == '':\n",
    "            self.size = 1\n",
    "        else:\n",
    "            self.size = int(quintuple[2])\n",
    "\n",
    "class Mention:\n",
    "    def __init__(self, name='', start=0, end=0, surface='', isSuffix = False, size=1):\n",
    "        self.name = name          # Identifier of the mention, e.g. T32\n",
    "        self.start = start        # Start of the word position (=node) in the text\n",
    "        self.end = end            # End of the word position (=node) in the text\n",
    "        self.surface = surface    # Surface text\n",
    "        self.note = ''            # AnnotatorNotes\n",
    "        self.typ = ''             # Reconstructed phrase type \n",
    "        self.isSuffix = isSuffix  # Boolean if mention is suffix\n",
    "        self.size = size          # wordsize of mention\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.surface \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.surface\n",
    "        \n",
    "class Coref:\n",
    "    def __init__(self):\n",
    "        self.id = ''\n",
    "        self.terms = []\n",
    "\n",
    "    def add(self, term):\n",
    "        self.terms.append(term)\n",
    "\n",
    "    def first(self):\n",
    "        # Dit is niet per se goed, bij nested mentions moet er ook naar\n",
    "        # t.end gekeken worden  \n",
    "        #sorteer eerst op t.isSuffix dan op t.start, omdat sorteren op start conservatief is. \n",
    "        # want False < True, dus suffix komt na word in tekstvolgorde\n",
    "        # sorteer of twee keys\n",
    "        \n",
    "        #return sorted(self.terms, key=lambda t: t.start)[0] #print first element in list\n",
    "        \n",
    "        lst = sorted(self.terms, key=lambda t: t.isSuffix)\n",
    "        return sorted(lst, key=lambda t: t.start)[0]\n",
    "    \n",
    "def error(*args, **kwargs):\n",
    "    print(*args, file=stderr, **kwargs)\n",
    "    exit(1)\n",
    "    \n",
    "def Get(node, fName):\n",
    "    '''\n",
    "    Helper function to parse the mention and coref \n",
    "    features stored in TF files in a structured way. \n",
    "    '''\n",
    "    valueStr = Fs(fName).v(node)\n",
    "    if not valueStr:\n",
    "        return None\n",
    "    parts = valueStr.split('|')\n",
    "    if len(parts) > 2:\n",
    "        error(f'There are more than 2 parts.')\n",
    "        \n",
    "    vd_list = []\n",
    "    vd_list.append(ValueData(parts[0].split(',')))\n",
    "    \n",
    "    if len(parts) > 1:\n",
    "        vd_list.append(ValueData(parts[1].split(',')))\n",
    "    else:\n",
    "        vd_list.append(ValueData(('', '0', '', '', ''))) # make empty tuple\n",
    "        vd_list[1].isSuffix = not vd_list[0].isSuffix # assign opposite Boolean of isSuffix\n",
    "\n",
    "    #check for isSuffix\n",
    "    if vd_list[0].isSuffix: \n",
    "        return (vd_list[1], vd_list[0])\n",
    "    else:\n",
    "        return (vd_list[0], vd_list[1])\n",
    "    \n",
    "    \n",
    "def FindMentionIndexByName(mention_list, name):\n",
    "    for i in range(len(mention_list)):\n",
    "        if mention_list[i].name == name:\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "def UpdateMentionNotes(mention_list, mention_notes):\n",
    "    notes_list = mention_notes.split(\"|\")\n",
    "    for note in notes_list:\n",
    "        (key, value) = note.split(\"-\", 1)\n",
    "        i = FindMentionIndexByName(mention_list, key)\n",
    "        mention_list[i].note = value\n",
    "        \n",
    "        \n",
    "def add_mention_to_coref(d, k, m):\n",
    "    '''\n",
    "    d = coref dict\n",
    "    k = key: 0 for singleton, or chapter:classnumber for coreference \n",
    "    m = mention\n",
    "    Check if key is in coref dict.\n",
    "    '''\n",
    "    \n",
    "    if not k in d:\n",
    "        d[k] = Coref()\n",
    "    d[k].add(m)\n",
    "\n",
    "def TexFabricParse(my_book_name, from_chapter, to_chapter):\n",
    "    suffix_error = []\n",
    "    coref_dict = {}\n",
    "    Mentions = []\n",
    "    singletons = Coref()\n",
    "    singletons.id = 'Singletons'\n",
    "    coref_dict[0] = singletons\n",
    "    \n",
    "    my_chapters = set(range(from_chapter, to_chapter+1))\n",
    "    for book in F.otype.s('book'):\n",
    "        book_name = T.bookName(book)\n",
    "        \n",
    "        for chn in L.d(book, 'chapter'):\n",
    "            chapter = F.chapter.v(chn)\n",
    "            if (\n",
    "                (my_book_name and book_name not in my_book_name)\n",
    "                or \n",
    "                (my_chapters and chapter not in my_chapters)\n",
    "            ):\n",
    "                continue\n",
    "            for phrase in L.d(chn, 'phrase'): \n",
    "                for word in L.d(phrase, 'word'):\n",
    "                    phr_atom = L.u(word, 'phrase_atom')[0]\n",
    "                    pa_words = L.d(phr_atom, 'word')\n",
    "                    last_word = pa_words[-1]\n",
    "                    boo, cha, ver = T.sectionFromNode(word)\n",
    "                    mentions = Get(word, 'mention') #tuple pair\n",
    "                    mention_notes = F.mentionNote.v(word)\n",
    "                    c = F.coref.v(word) \n",
    "                    mention_list = []\n",
    "                    if mentions:\n",
    "                        for i in range(len(mentions)):\n",
    "                            assert(mentions[i].ct == 'T' or mentions[i].ct == '')\n",
    "                            name = f'{mentions[i].ct}{mentions[i].seqNum}'\n",
    "                            \n",
    "                            #assert(mentions[i].isSuffix == (i == 1))\n",
    "                            if mentions[i].isSuffix != (i == 1):\n",
    "                                suffix_error.append((word, f'{cha}:{ver}', mentions[i].wordPart, \n",
    "                                                     f'T{mentions[i].seqNum}'))\n",
    "                            if mentions[i].size == 1:\n",
    "                                mention_list.append(Mention(name, word, word, mentions[i].wordPart, \n",
    "                                                            i == 1, mentions[i].size))\n",
    "                            else:\n",
    "                                mention_list.append(Mention(name, word, last_word, mentions[i].wordPart, \n",
    "                                                            i == 1, mentions[i].size))\n",
    "                    \n",
    "                    if mention_notes:\n",
    "                        UpdateMentionNotes(mention_list, mention_notes)\n",
    "          \n",
    "                    corefs = Get(word, 'coref')\n",
    "                    if corefs:\n",
    "                        # check for empty corefs and singletons \n",
    "                        for i in range(len(corefs)):\n",
    "                            if corefs[i].ct == '':\n",
    "                                continue\n",
    "                            if corefs[i].ct == 'T':\n",
    "                                key = 0\n",
    "                            else:\n",
    "                                key = f'{chapter}:{corefs[i].seqNum}'\n",
    "                            add_mention_to_coref(coref_dict, key, mention_list[i])\n",
    "                            Mentions.append(mention_list[i])\n",
    "        \n",
    "    return Mentions, coref_dict, suffix_error\n",
    "\n",
    "def EnrichMentions(mentions):\n",
    "    '''\n",
    "    Takes mention_list and assigns correct \n",
    "    phrase atom type (`pa_typ`) to m.typ. \n",
    "    - Uses the word node of m.start to retrieve relevant \n",
    "    phrase atom information. \n",
    "    - If mention node is the same as the phrase atom, \n",
    "    then the same `pa_typ` is assigned. \n",
    "    - If it is not the same, the m.typ is \n",
    "    taken from the phrase dependent part of speech (`pdp`). \n",
    "    - reconstructed phrase types (`rpt`) that seem to be wrong,\n",
    "    i.e. mentions that are `prep` or `adverb` or `art' are stored\n",
    "    in the list: reconsider_rpt. \n",
    "    '''\n",
    "    \n",
    "    reconsider_rpt = []\n",
    "    \n",
    "    for m in mentions:\n",
    "        boo, cha, ver = T.sectionFromNode(m.start)\n",
    "        phr_atom = L.u(m.start, 'phrase_atom')[0]\n",
    "        pa_typ = F.typ.v(phr_atom)\n",
    "        pa_text = T.text(phr_atom, fmt='text-trans-plain')\n",
    "        pa_words = L.d(phr_atom, 'word')\n",
    "        pdp = F.pdp.v(m.start)\n",
    "        vt = F.vt.v(m.start)#'ptca'\n",
    "        \n",
    "        if m.isSuffix:\n",
    "            m.typ = 'Sffx'\n",
    "        # if mention nodes are the same as phrase atom nodes \n",
    "        elif len(pa_words) == 1 and not m.isSuffix:\n",
    "            m.typ = pa_typ\n",
    "        \n",
    "        elif len(pa_words) > 1 and pa_typ == 'NP':\n",
    "            m.typ = pa_typ\n",
    "        elif pa_typ == 'VP' and vt == 'ptca':\n",
    "            m.typ = 'PtcP'\n",
    "        elif pa_typ == 'VP':\n",
    "            m.typ = pa_typ\n",
    "        elif pdp == 'nmpr':\n",
    "            m.typ = 'PrNP'\n",
    "        elif pdp == 'subs':\n",
    "            m.typ = 'NP'\n",
    "        elif pdp == 'prde':\n",
    "            m.typ = 'DPrP'\n",
    "        elif pdp == 'prps':\n",
    "            m.typ = 'PPrP'\n",
    "        #reconsider these annotations, stored in reconsider_rpt\n",
    "        elif pdp == 'adjv':\n",
    "            m.typ = 'AdjP'  \n",
    "        else:\n",
    "            m.typ = pdp\n",
    "            reconsider_rpt.append((f'{cha}:{ver}', m.start, m.end, m.surface, pdp, pa_words, pa_text, pa_typ))\n",
    "        #print(m.start, m.end, m.surface, '\\t', pdp, m.typ, '\\t', (pa_words, pa_text, pa_typ))\n",
    "    return reconsider_rpt\n",
    "\n",
    "\n",
    "def FindMentionByRPT(c, typ):\n",
    "    for m in c.terms:\n",
    "        if m.typ == typ:\n",
    "            return m\n",
    "    \n",
    "def Identify(c):\n",
    "    rpt_order = ['PrNP', 'NP', 'PtcP', 'VP', 'PPrP', 'Sffx', 'DPrP']\n",
    "    for typ in rpt_order:\n",
    "        m = FindMentionByRPT(c, typ)\n",
    "        if m:\n",
    "            c.id = m.surface\n",
    "            return \n",
    "    c.id = c.first()\n",
    "\n",
    "def AssignIdentity(corefs):\n",
    "    for key, c in corefs.items():\n",
    "        if key != 0:\n",
    "            Identify(c)\n",
    "\n",
    "def ParseAnnotations(my_book_name, from_chapter, to_chapter):\n",
    "    mentions, corefs, suffix_errors = TexFabricParse(my_book_name, from_chapter, to_chapter)\n",
    "    reconsider_rpt = EnrichMentions(mentions)\n",
    "    AssignIdentity(corefs)\n",
    "    return mentions, corefs, suffix_errors, reconsider_rpt\n",
    "\n",
    "\n",
    "\n",
    "def GetOverallData(corefs, mentions):\n",
    "    overall_dict = Counter()\n",
    "    \n",
    "    for k, c in corefs.items():\n",
    "        if k != 0:\n",
    "            overall_dict['classes'] += 1\n",
    "        for m in c.terms:\n",
    "            if k == 0:\n",
    "                overall_dict['singletons'] += 1\n",
    "            overall_dict['mentions'] += 1\n",
    "    for m in mentions:\n",
    "        if m.note:\n",
    "            overall_dict['notes'] += 1\n",
    "            \n",
    "    return overall_dict\n",
    "\n",
    "def GetGraphData(corefs):\n",
    "    annotation_errors = []\n",
    "    pos_dict = defaultdict(lambda: defaultdict(int))\n",
    "    pronoun_dict = defaultdict(lambda: defaultdict(int))\n",
    "    pronoun_pos_class_dict = defaultdict(lambda: defaultdict(int))\n",
    "    pronoun_pos_sing_dict = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for k, c in corefs.items():\n",
    "        if k != 0:\n",
    "            pos_dict['first in chain'][c.first().typ] += 1     \n",
    "        for m in c.terms:\n",
    "            # Not necessary anymore, but left here to make explicit that suffix \n",
    "            # is made into a separate mention type\n",
    "            pa_typ = 'Sffx' if m.isSuffix else m.typ \n",
    "            if k != 0:\n",
    "                pos_dict['in class'][pa_typ] += 1\n",
    "                if pa_typ in {'VP', 'PPrP'}:\n",
    "                    if converse_pgn(F, m.start) != '':\n",
    "                        pronoun_dict['in class'][converse_pgn(F, m.start)] += 1\n",
    "                        pronoun_pos_class_dict[pa_typ][converse_pgn(F, m.start)] += 1\n",
    "                elif m.isSuffix:\n",
    "                    if m.surface not in suffix_dict:\n",
    "                        annotation_errors.append((k, m.start, m.surface, m.isSuffix))\n",
    "                    else:\n",
    "                        pronoun_dict['in class'][suffix_dict[m.surface][0]] += 1\n",
    "                        pronoun_pos_class_dict[pa_typ][suffix_dict[m.surface][0]] += 1\n",
    "            else: #'Singletons'\n",
    "                pos_dict['singleton'][pa_typ] += 1\n",
    "                if pa_typ in {'VP', 'PPrP'}:\n",
    "                    if converse_pgn(F, m.start) != '':\n",
    "                        pronoun_dict['singleton'][converse_pgn(F, m.start)] += 1\n",
    "                        pronoun_pos_sing_dict[pa_typ][converse_pgn(F, m.start)] += 1\n",
    "                elif m.isSuffix:\n",
    "                    if m.surface not in suffix_dict:\n",
    "                        annotation_errors.append((k, m.start, m.surface, m.isSuffix))\n",
    "                    else:\n",
    "                        pronoun_dict['singleton'][suffix_dict[m.surface][0]] += 1\n",
    "                        pronoun_pos_sing_dict[pa_typ][suffix_dict[m.surface][0]] += 1\n",
    "            \n",
    "            pos_dict['total'][pa_typ] += 1\n",
    "            \n",
    "    return pos_dict, pronoun_dict, pronoun_pos_class_dict, pronoun_pos_sing_dict\n",
    "\n",
    "def MakePandasTables(corefs, mentions):\n",
    "    \n",
    "    overall_dict = GetOverallData(corefs, mentions) \n",
    "    pos_dict, pronoun_dict, pronoun_pos_class_dict, \\\n",
    "    pronoun_pos_sing_dict = GetGraphData(corefs)\n",
    "     \n",
    "    overall_df = pd.DataFrame.from_dict(overall_dict, \n",
    "                            orient='index',\n",
    "                            columns = ['total'],\n",
    "                            ).fillna(0).astype(int).sort_values(\n",
    "                            by=['total'], ascending=False)\n",
    "    \n",
    "    # part of speech for class and singletons data frame\n",
    "    pos_df = pd.DataFrame.from_dict(pos_dict, \n",
    "                                      orient='index', \n",
    "                                      ).fillna(0).astype(int)\n",
    "    \n",
    "    pos_df = pos_df.sort_values(by=['first in chain', 'in class', 'singleton'], \n",
    "                                ascending=False, axis=1)\n",
    "    \n",
    "    pos_df['total_type'] = pos_df.sum(axis=1)\n",
    "    pos_df = pos_df.sort_values(by=['total_type'], ascending=False)\n",
    "    \n",
    "                # percentage\n",
    "    tot_chain = pos_df.loc['first in chain']['total_type']\n",
    "    tot_chain\n",
    "    pos_df.loc['% chain',:] = round((pos_df.loc['first in chain',:] / \n",
    "                                              tot_chain) * 100)\n",
    "    tot_tot = pos_df.loc['total']['total_type']\n",
    "    pos_df.loc['% total',:] = round((pos_df.loc['total',:] / \n",
    "                                              tot_tot) * 100)\n",
    "    pos_df = pos_df.fillna(0).astype(int)\n",
    "    pos_df = pos_df.reindex(['in class', 'singleton', 'total', '% total', 'first in chain', '% chain'])\n",
    "    \n",
    "    \n",
    "    # pronoun for class and singletons data frame \n",
    "    pronoun_df = pd.DataFrame.from_dict(pronoun_dict, \n",
    "                                      orient='index',\n",
    "                                      ).fillna(0).astype(int)\n",
    "    \n",
    "    pronoun_df = pronoun_df.reindex(sorted(pronoun_df.columns), axis=1)\n",
    "    pronoun_df['total_pgn'] = pronoun_df.sum(axis=1)\n",
    "    pronoun_df = pronoun_df.sort_values(by=['total_pgn'], ascending=False)\n",
    "                # percentage\n",
    "    tot_pron = pronoun_df['total_pgn'].sum(axis=0)\n",
    "    pronoun_df.loc['total',:] = pronoun_df.sum(axis=0)\n",
    "    pronoun_df.loc['% total',:] = round((pronoun_df.loc['total',:] / tot_pron) * 100)\n",
    "    \n",
    "    pronoun_df = pronoun_df.fillna(0).astype(int)\n",
    "    \n",
    "    # part of speech and pronouns for class data frame\n",
    "    pronoun_pos_class_df = pd.DataFrame.from_dict(pronoun_pos_class_dict, \n",
    "                                                       orient='index').fillna(0).astype(int)\n",
    "    pronoun_pos_class_df = pronoun_pos_class_df.reindex(sorted(pronoun_pos_class_df.columns), \n",
    "                                                        axis=1)\n",
    "    pronoun_pos_class_df['total_pgn'] = pronoun_pos_class_df.sum(axis=1)\n",
    "    pronoun_pos_class_df = pronoun_pos_class_df.sort_values(by=['total_pgn'], \n",
    "                                                            ascending=False)\n",
    "                # percentage\n",
    "    tot_pronoun_pos_class = pronoun_pos_class_df['total_pgn'].sum(axis=0)\n",
    "    pronoun_pos_class_df.loc['total',:] = pronoun_pos_class_df.sum(axis=0)\n",
    "    pronoun_pos_class_df.loc['% total',:] = round((pronoun_pos_class_df.loc['total',:] / \n",
    "                                                   tot_pronoun_pos_class) * 100)\n",
    "    pronoun_pos_class_df = pronoun_pos_class_df.fillna(0).astype(int)\n",
    "    \n",
    "    # part of speech and pronouns for singletons data frame\n",
    "    pronoun_pos_sing_df = pd.DataFrame.from_dict(pronoun_pos_sing_dict, \n",
    "                                                       orient='index').fillna(0).astype(int)\n",
    "    pronoun_pos_sing_df = pronoun_pos_sing_df.reindex(sorted(pronoun_pos_sing_df.columns), \n",
    "                                                      axis=1)\n",
    "    pronoun_pos_sing_df['total_pgn'] = pronoun_pos_sing_df.sum(axis=1)\n",
    "    pronoun_pos_sing_df = pronoun_pos_sing_df.sort_values(by=['total_pgn'], \n",
    "                                                          ascending=False)\n",
    "                # percentage\n",
    "    tot_pronoun_pos_sing = pronoun_pos_sing_df['total_pgn'].sum(axis=0)\n",
    "    pronoun_pos_sing_df.loc['total',:] = pronoun_pos_sing_df.sum(axis=0)\n",
    "    pronoun_pos_sing_df.loc['% total',:] = round((pronoun_pos_sing_df.loc['total',:] / \n",
    "                                                  tot_pronoun_pos_sing) * 100)\n",
    "    pronoun_pos_sing_df = pronoun_pos_sing_df.fillna(0).astype(int)\n",
    "    \n",
    "    \n",
    "    return overall_df, pos_df, pronoun_df, pronoun_pos_class_df, pronoun_pos_sing_df\n",
    "\n",
    "#MakePandasTables(coref_dict, mentions_list)\n",
    "\n",
    "def PrintThisTable(df):\n",
    "    return df \n",
    "\n",
    "def PrintPossibleCorrections(suffix_errors, reconsider_rpt):\n",
    "    \n",
    "    if len(suffix_errors) == 0:\n",
    "        print(f'There are {len(suffix_errors)} annotation errors for the specified corpus', '\\n')\n",
    "    else:\n",
    "        print(f'There are {len(suffix_errors)} possible annotation errors you may need to reconsider:', '\\n')\n",
    "        print(f'The order is: node, text, lexeme, brat id')  \n",
    "        for i in suffix_errors:\n",
    "            print(i, '\\n')\n",
    "    \n",
    "    if len(reconsider_rpt) == 0:\n",
    "        print(f'There are {len(reconsider_rpt)} reconstructed phrase type errors for the specified corpus', '\\n')\n",
    "    else:\n",
    "        print(f'There are {len(reconsider_rpt)} possible erroneous reconstructed phrase types you may need to reconsider:', '\\n')\n",
    "        print(f'The order is: text, start node, end node, lexeme, pdp, (phrase atom nodes), lexeme(s), type')\n",
    "        for i in reconsider_rpt:\n",
    "            print(i, '\\n')\n",
    "            \n",
    "divide = '-'*70\n",
    "\n",
    "def PrintCorefPattern(c, k, suffix_errors):\n",
    "    print(f'C{k} Who/what: {c.id} /', end=' ')\n",
    "    if c.id != 'Singletons':\n",
    "        print(f'first: {c.first().surface}, type: {c.first().typ}', end='\\n')\n",
    "    print(divide)\n",
    "    bad_words = [e[2] for e in suffix_errors]\n",
    "    for m in c.terms:\n",
    "        if m.typ in {'VP', 'PPrP'} and not m.isSuffix:\n",
    "            pgn = converse_pgn(F, m.start)\n",
    "            print(f'{m.surface} -{m.typ} {pgn}', f'{m.note}  ', end=' ')\n",
    "        \n",
    "        elif m.isSuffix and m.surface in bad_words:\n",
    "            print(f'{m.surface} -{m.typ} !CORRUPT ANN', f'{m.note}  ', end=' ')\n",
    "        \n",
    "        elif m.isSuffix:\n",
    "            pgn_suffix = suffix_dict[m.surface][0]\n",
    "            print(f'{m.surface} -{m.typ} {pgn_suffix}', f'{m.note}  ', end=' ')\n",
    "        else:\n",
    "            print(f'{m.surface} -{m.typ}', f'{m.note}  ', end=' ')\n",
    "    print('\\n')\n",
    "\n",
    "def PrintPatternsAndNotes(cd, suffix_errors):\n",
    "    for k in cd:\n",
    "        if k != 0:\n",
    "            PrintCorefPattern(cd[k], k, suffix_errors)\n",
    "    PrintCorefPattern(cd[0], '0', suffix_errors)\n",
    "    \n",
    "def PrintCorefID(corefs):\n",
    "    '''\n",
    "    Print coref class that is sorted \n",
    "    by alef-betical order on coref id.\n",
    "    '''\n",
    "    \n",
    "    tr_asc = '#/<=>BCDFGHJKLMNPQRSTVWXYZ_'\n",
    "    tr_heb = '/=_>BGDHWZXVJKLMNS<PYQRF#CT'\n",
    "    \n",
    "    etcbc_table = str.maketrans(tr_heb, tr_asc)\n",
    "    \n",
    "    classes = {k:v for (k,v) in corefs.items() if k != 0}\n",
    "    \n",
    "    keys = sorted(classes, key=lambda c: classes[c].id.translate(etcbc_table))\n",
    "    \n",
    "    for k in keys:\n",
    "        PrintCoref(classes[k], k)\n",
    "    #PrintCoref(classes[0], '0')\n",
    "\n",
    "def PrintCoref(c, k):\n",
    "    print(f'C{k} Who/what: {c.id} /', end=' ')\n",
    "    if c.id != 'Singletons':\n",
    "        print(f'first: {c.first().surface}, type: {c.first().typ}', end='\\n')\n",
    "    print(divide)\n",
    "    print(c.terms, '\\n')\n",
    "\n",
    "def PrintSurvey(cd):\n",
    "    for k in cd:\n",
    "        if k != 0:\n",
    "            PrintCoref(cd[k], k)\n",
    "    PrintCoref(cd[0], '0')\n",
    "    \n",
    "def ExportToLatex(output_loc, file_name, data_frame, indx = True):\n",
    "    with open(f'{output_loc}{file_name}.tex','w') as texf:\n",
    "        texf.write(data_frame.to_latex(index=indx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_book_name = 'Psalms'\n",
    "from_chapter = 1\n",
    "to_chapter = 150\n",
    "\n",
    "mentions, corefs, suffix_errors, reconsider_rpt = ParseAnnotations(my_book_name, from_chapter, to_chapter)\n",
    "\n",
    "overall_df, pos_df, \\\n",
    "pronoun_df, pronoun_pos_class_df, \\\n",
    "pronoun_pos_sing_df = MakePandasTables(corefs, mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mentions</th>\n",
       "      <td>18570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>singletons</th>\n",
       "      <td>4789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classes</th>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notes</th>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            total\n",
       "mentions    18570\n",
       "singletons   4789\n",
       "classes      2000\n",
       "notes         715"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PrintThisTable(overall_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NP</th>\n",
       "      <th>VP</th>\n",
       "      <th>Sffx</th>\n",
       "      <th>PrNP</th>\n",
       "      <th>DPrP</th>\n",
       "      <th>PPrP</th>\n",
       "      <th>PtcP</th>\n",
       "      <th>AdjP</th>\n",
       "      <th>CP</th>\n",
       "      <th>AdvP</th>\n",
       "      <th>PP</th>\n",
       "      <th>prep</th>\n",
       "      <th>advb</th>\n",
       "      <th>art</th>\n",
       "      <th>total_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in class</th>\n",
       "      <td>3087</td>\n",
       "      <td>4982</td>\n",
       "      <td>4569</td>\n",
       "      <td>795</td>\n",
       "      <td>31</td>\n",
       "      <td>287</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>singleton</th>\n",
       "      <td>4405</td>\n",
       "      <td>97</td>\n",
       "      <td>40</td>\n",
       "      <td>164</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>7492</td>\n",
       "      <td>5079</td>\n",
       "      <td>4609</td>\n",
       "      <td>959</td>\n",
       "      <td>46</td>\n",
       "      <td>289</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>18570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>% total</th>\n",
       "      <td>40</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first in chain</th>\n",
       "      <td>1001</td>\n",
       "      <td>702</td>\n",
       "      <td>142</td>\n",
       "      <td>122</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>% chain</th>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  NP    VP  Sffx  PrNP  DPrP  PPrP  PtcP  AdjP  CP  AdvP  PP  \\\n",
       "in class        3087  4982  4569   795    31   287    16     2   7     3   2   \n",
       "singleton       4405    97    40   164    15     2     1    24   3    18   0   \n",
       "total           7492  5079  4609   959    46   289    17    26  10    21   2   \n",
       "% total           40    27    25     5     0     2     0     0   0     0   0   \n",
       "first in chain  1001   702   142   122    13    12     4     2   1     1   0   \n",
       "% chain           50    35     7     6     1     1     0     0   0     0   0   \n",
       "\n",
       "                prep  advb  art  total_type  \n",
       "in class           0     0    0       13781  \n",
       "singleton         14     5    1        4789  \n",
       "total             14     5    1       18570  \n",
       "% total            0     0    0         100  \n",
       "first in chain     0     0    0        2000  \n",
       "% chain            0     0    0         100  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PrintThisTable(pos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1upl</th>\n",
       "      <th>p1usg</th>\n",
       "      <th>p2fsg</th>\n",
       "      <th>p2mpl</th>\n",
       "      <th>p2msg</th>\n",
       "      <th>p3fpl</th>\n",
       "      <th>p3fsg</th>\n",
       "      <th>p3mpl</th>\n",
       "      <th>p3msg</th>\n",
       "      <th>p3upl</th>\n",
       "      <th>ufpl</th>\n",
       "      <th>ufsg</th>\n",
       "      <th>umpl</th>\n",
       "      <th>umsg</th>\n",
       "      <th>uuu</th>\n",
       "      <th>total_pgn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in class</th>\n",
       "      <td>332</td>\n",
       "      <td>2415</td>\n",
       "      <td>29</td>\n",
       "      <td>282</td>\n",
       "      <td>2282</td>\n",
       "      <td>21</td>\n",
       "      <td>344</td>\n",
       "      <td>1172</td>\n",
       "      <td>2089</td>\n",
       "      <td>386</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>91</td>\n",
       "      <td>284</td>\n",
       "      <td>80</td>\n",
       "      <td>9833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>singleton</th>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>343</td>\n",
       "      <td>2428</td>\n",
       "      <td>29</td>\n",
       "      <td>292</td>\n",
       "      <td>2298</td>\n",
       "      <td>21</td>\n",
       "      <td>347</td>\n",
       "      <td>1180</td>\n",
       "      <td>2123</td>\n",
       "      <td>392</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>100</td>\n",
       "      <td>292</td>\n",
       "      <td>93</td>\n",
       "      <td>9965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>% total</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           p1upl  p1usg  p2fsg  p2mpl  p2msg  p3fpl  p3fsg  p3mpl  p3msg  \\\n",
       "in class     332   2415     29    282   2282     21    344   1172   2089   \n",
       "singleton     11     13      0     10     16      0      3      8     34   \n",
       "total        343   2428     29    292   2298     21    347   1180   2123   \n",
       "% total        3     24      0      3     23      0      3     12     21   \n",
       "\n",
       "           p3upl  ufpl  ufsg  umpl  umsg  uuu  total_pgn  \n",
       "in class     386     5    21    91   284   80       9833  \n",
       "singleton      6     0     1     9     8   13        132  \n",
       "total        392     5    22   100   292   93       9965  \n",
       "% total        4     0     0     1     3    1        100  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PrintThisTable(pronoun_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1upl</th>\n",
       "      <th>p1usg</th>\n",
       "      <th>p2fsg</th>\n",
       "      <th>p2mpl</th>\n",
       "      <th>p2msg</th>\n",
       "      <th>p3fpl</th>\n",
       "      <th>p3fsg</th>\n",
       "      <th>p3mpl</th>\n",
       "      <th>p3msg</th>\n",
       "      <th>p3upl</th>\n",
       "      <th>ufpl</th>\n",
       "      <th>ufsg</th>\n",
       "      <th>umpl</th>\n",
       "      <th>umsg</th>\n",
       "      <th>uuu</th>\n",
       "      <th>total_pgn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VP</th>\n",
       "      <td>91</td>\n",
       "      <td>768</td>\n",
       "      <td>29</td>\n",
       "      <td>254</td>\n",
       "      <td>998</td>\n",
       "      <td>20</td>\n",
       "      <td>234</td>\n",
       "      <td>589</td>\n",
       "      <td>1131</td>\n",
       "      <td>386</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>91</td>\n",
       "      <td>284</td>\n",
       "      <td>80</td>\n",
       "      <td>4981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sffx</th>\n",
       "      <td>233</td>\n",
       "      <td>1565</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1167</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>559</td>\n",
       "      <td>909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPrP</th>\n",
       "      <td>8</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>332</td>\n",
       "      <td>2415</td>\n",
       "      <td>29</td>\n",
       "      <td>282</td>\n",
       "      <td>2282</td>\n",
       "      <td>21</td>\n",
       "      <td>344</td>\n",
       "      <td>1172</td>\n",
       "      <td>2089</td>\n",
       "      <td>386</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>91</td>\n",
       "      <td>284</td>\n",
       "      <td>80</td>\n",
       "      <td>9833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>% total</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         p1upl  p1usg  p2fsg  p2mpl  p2msg  p3fpl  p3fsg  p3mpl  p3msg  p3upl  \\\n",
       "VP          91    768     29    254    998     20    234    589   1131    386   \n",
       "Sffx       233   1565      0     28   1167      0    104    559    909      0   \n",
       "PPrP         8     82      0      0    117      1      6     24     49      0   \n",
       "total      332   2415     29    282   2282     21    344   1172   2089    386   \n",
       "% total      3     25      0      3     23      0      3     12     21      4   \n",
       "\n",
       "         ufpl  ufsg  umpl  umsg  uuu  total_pgn  \n",
       "VP          5    21    91   284   80       4981  \n",
       "Sffx        0     0     0     0    0       4565  \n",
       "PPrP        0     0     0     0    0        287  \n",
       "total       5    21    91   284   80       9833  \n",
       "% total     0     0     1     3    1        100  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PrintThisTable(pronoun_pos_class_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1upl</th>\n",
       "      <th>p1usg</th>\n",
       "      <th>p2mpl</th>\n",
       "      <th>p2msg</th>\n",
       "      <th>p3fsg</th>\n",
       "      <th>p3mpl</th>\n",
       "      <th>p3msg</th>\n",
       "      <th>p3upl</th>\n",
       "      <th>ufsg</th>\n",
       "      <th>umpl</th>\n",
       "      <th>umsg</th>\n",
       "      <th>uuu</th>\n",
       "      <th>total_pgn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VP</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sffx</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPrP</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>% total</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         p1upl  p1usg  p2mpl  p2msg  p3fsg  p3mpl  p3msg  p3upl  ufsg  umpl  \\\n",
       "VP           0      5      9     12      1      4     28      6     1     9   \n",
       "Sffx        11      7      1      4      2      3      6      0     0     0   \n",
       "PPrP         0      1      0      0      0      1      0      0     0     0   \n",
       "total       11     13     10     16      3      8     34      6     1     9   \n",
       "% total      8     10      8     12      2      6     26      5     1     7   \n",
       "\n",
       "         umsg  uuu  total_pgn  \n",
       "VP          8   13         96  \n",
       "Sffx        0    0         34  \n",
       "PPrP        0    0          2  \n",
       "total       8   13        132  \n",
       "% total     6   10        100  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PrintThisTable(pronoun_pos_sing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
