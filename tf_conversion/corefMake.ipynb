{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix: \n",
    "\n",
    "* When selecting only a few chapters for conversion with `selectChapters = {1, 2}`, all earlier done conversions to TF are overwritten.\n",
    "\n",
    "* When the conversion of all annotations for different books have been done, and a new push is done for one specific book, all annotions are overwritten except for the updated data of one book. \n",
    "\n",
    "Work around for now:\n",
    "\n",
    "* Correct annotations, and push al annotated books one by one again. It just costs a minute, but needs a fix anyway. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/tf-small.png\" width=\"90\"/>\n",
    "<img align=\"right\" src=\"images/etcbc.png\" width=\"100\"/>\n",
    "\n",
    "# From Coreference Annotations to Text-Fabric Data\n",
    "\n",
    "The code in this notebook converts the coreference resolution annotations done in brat to Text-Fabric data. Just run the cells, and follow the instructions written in the cells above the code or else in the code which are indicated by a `#`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'erwich/roorda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Modules and Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import rmtree\n",
    "from glob import glob\n",
    "\n",
    "from tf.app import use\n",
    "from tf.fabric import Fabric\n",
    "\n",
    "from utils import suffix_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Administration\n",
    "\n",
    "The location on your PC where the annotated data is taken from for the TF conversion has the form: \n",
    "* `{OUTPUT_BASE}/{bookName}/{ANNOTATE}/*.ann`\n",
    "\n",
    "For the standoff files the form of the location is: \n",
    "* `{OUTPUT_BASE}/{bookName}/{STANDOFF}/{fileName}.tsv`\n",
    "\n",
    "The location on your PC where the converted TF data is stored has the form: \n",
    "* `{GITHUB_BASE}/{ORG}/{REPO}/{PATH}/{VERSION}`\n",
    "\n",
    "All the CONSTANTS can be specified in the cell below. It is possible to convert coreference annotations, if existent of course, for any Hebrew Bible book. The book is specified with `bookName` in the function `getFeatures()` below, e.g. `getFeatures('Psalms')`\n",
    "\n",
    "The textual data of the BHSA that form the basis of the coreference annotations has been generated in the fixed 2017 version, so do not change this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have used the fixed 2017 data, do not change this\n",
    "VERSION = '2017'\n",
    "\n",
    "# Enter your GitHub repo \n",
    "ORG = 'cmerwich'\n",
    "\n",
    "# The locations where you want to store the converted data \n",
    "REPO = 'participant-analysis' \n",
    "PATH = 'coreference/tf'\n",
    "\n",
    "# The output base indicates where the programs below can find the annotated data\n",
    "OUTPUT_BASE = os.path.expanduser('~/Sites/brat/data/coref')\n",
    "\n",
    "# This OUTPUT_BASE is used for coreference data that Gyusang Jin has produced for Numbers\n",
    "#OUTPUT_BASE = os.path.expanduser('~/Sites/brat/data/gyusang/coref')\n",
    "\n",
    "# GitHub location on your computer\n",
    "GITHUB_BASE = os.path.expanduser('~/github')\n",
    "\n",
    "# This is the annotation folder \n",
    "ANNOTATE = f'annotate'\n",
    "\n",
    "# The standoff folder is important for the TF conversion \n",
    "STANDOFF = f'standoff'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the TF App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b title=\"local release\">TF-app:</b> <span title=\"rv2.3.0=#113c0687cfce3077734dac1844d244d20f4ace6f offline under ~/text-fabric-data\">~/text-fabric-data/annotation/app-bhsa/code</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local release\">data:</b> <span title=\"rv1.6=#bac4a9f5a2bbdede96ba6caea45e762fe88f88c5 offline under ~/text-fabric-data\">~/text-fabric-data/etcbc/bhsa/tf/2017</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local release\">data:</b> <span title=\"r1.2=#1ac68e976ee4a7f23eb6bb4c6f401a033d0ec169 offline under ~/text-fabric-data\">~/text-fabric-data/etcbc/phono/tf/2017</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local release\">data:</b> <span title=\"r1.2 offline under ~/text-fabric-data\">~/text-fabric-data/etcbc/parallels/tf/2017</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Text-Fabric:</b> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/cheatsheet.html\" title=\"text-fabric-api\">Text-Fabric API 8.3.3</a>, <a target=\"_blank\" href=\"https://github.com/annotation/app-bhsa\" title=\"bhsa TF-app\">app-bhsa</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/about/searchusage.html\" title=\"Search Templates Introduction and Reference\">Search Reference</a><br><b>Data:</b> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/0_home\" title=\"provenance of BHSA = Biblia Hebraica Stuttgartensia Amstelodamensis\">BHSA</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/writing/hebrew.html\" title=\"How TF features represent text\">Character table</a>, <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/0_home\" title=\"BHSA feature documentation\">Feature docs</a><br><b>Features:</b><br><details><summary><b>Parallel Passages</b></summary><b><i><a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/parallels/blob/master/programs/parallels.ipynb\" title=\"~/text-fabric-data/etcbc/parallels/tf/2017/crossref.tf\">crossref</a></i></b><br></details><details><summary><b>BHSA = Biblia Hebraica Stuttgartensia Amstelodamensis</b></summary><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/book\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/book.tf\">book</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/book@ll\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/book@am.tf\">book@ll</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/chapter\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/chapter.tf\">chapter</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/code\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/code.tf\">code</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/det\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/det.tf\">det</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/domain\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/domain.tf\">domain</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/freq_lex\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/freq_lex.tf\">freq_lex</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/function\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/function.tf\">function</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_cons\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/g_cons.tf\">g_cons</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_cons_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/g_cons_utf8.tf\">g_cons_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_lex\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/g_lex.tf\">g_lex</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_lex_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/g_lex_utf8.tf\">g_lex_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_word\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/g_word.tf\">g_word</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_word_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/g_word_utf8.tf\">g_word_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/gloss\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/gloss.tf\">gloss</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/gn\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/gn.tf\">gn</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/label\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/label.tf\">label</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/language\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/language.tf\">language</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/lex\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/lex.tf\">lex</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/lex_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/lex_utf8.tf\">lex_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/ls\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/ls.tf\">ls</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/nametype\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/nametype.tf\">nametype</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/nme\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/nme.tf\">nme</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/nu\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/nu.tf\">nu</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/number\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/number.tf\">number</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/otype\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/otype.tf\">otype</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/pargr\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/pargr.tf\">pargr</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/pdp\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/pdp.tf\">pdp</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/pfm\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/pfm.tf\">pfm</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/prs\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/prs.tf\">prs</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/prs_gn\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/prs_gn.tf\">prs_gn</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/prs_nu\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/prs_nu.tf\">prs_nu</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/prs_ps\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/prs_ps.tf\">prs_ps</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/ps\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/ps.tf\">ps</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/qere\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/qere.tf\">qere</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/qere_trailer\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/qere_trailer.tf\">qere_trailer</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/qere_trailer_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/qere_trailer_utf8.tf\">qere_trailer_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/qere_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/qere_utf8.tf\">qere_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/rank_lex\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/rank_lex.tf\">rank_lex</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/rela\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/rela.tf\">rela</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/sp\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/sp.tf\">sp</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/st\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/st.tf\">st</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/tab\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/tab.tf\">tab</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/trailer\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/trailer.tf\">trailer</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/trailer_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/trailer_utf8.tf\">trailer_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/txt\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/txt.tf\">txt</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/typ\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/typ.tf\">typ</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/uvf\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/uvf.tf\">uvf</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/vbe\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/vbe.tf\">vbe</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/vbs\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/vbs.tf\">vbs</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/verse\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/verse.tf\">verse</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/voc_lex\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/voc_lex.tf\">voc_lex</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/voc_lex_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/voc_lex_utf8.tf\">voc_lex_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/vs\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/vs.tf\">vs</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/vt\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/vt.tf\">vt</a><br><b><i><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/mother\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/mother.tf\">mother</a></i></b><br><b><i><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/omap@ll\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/omap@2016-2017.tf\">omap@ll</a></i></b><br><b><i><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/oslots\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2017/oslots.tf\">oslots</a></i></b><br></details><details><summary><b>Phonetic Transcriptions</b></summary><a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/phono/blob/master/programs/phono.ipynb\" title=\"~/text-fabric-data/etcbc/phono/tf/2017/phono.tf\">phono</a><br><a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/phono/blob/master/programs/phono.ipynb\" title=\"~/text-fabric-data/etcbc/phono/tf/2017/phono_trailer.tf\">phono_trailer</a><br></details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>tr.tf.ltr, td.tf.ltr, th.tf.ltr { text-align: left ! important;}\n",
       "tr.tf.rtl, td.tf.rtl, th.tf.rtl { text-align: right ! important;}\n",
       "@font-face {\n",
       "  font-family: \"Gentium Plus\";\n",
       "  src: local('Gentium Plus'), local('GentiumPlus'),\n",
       "    url('/server/static/fonts/GentiumPlus-R.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/GentiumPlus-R.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Ezra SIL\";\n",
       "  src: local('Ezra SIL'), local('EzraSIL'),\n",
       "    url('/server/static/fonts/SILEOT.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SILEOT.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"SBL Hebrew\";\n",
       "  src: local('SBL Hebrew'), local('SBLHebrew'),\n",
       "    url('/server/static/fonts/SBL_Hbrw.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SBL_Hbrw.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Estrangelo Edessa\";\n",
       "  src: local('Estrangelo Edessa'), local('EstrangeloEdessa');\n",
       "    url('/server/static/fonts/SyrCOMEdessa.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SyrCOMEdessa.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: AmiriQuran;\n",
       "  font-style: normal;\n",
       "  font-weight: 400;\n",
       "  src: local('Amiri Quran'), local('AmiriQuran'),\n",
       "    url('/server/static/fonts/AmiriQuran.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/AmiriQuran.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: AmiriQuranColored;\n",
       "  font-style: normal;\n",
       "  font-weight: 400;\n",
       "  src: local('Amiri Quran Colored'), local('AmiriQuranColored'),\n",
       "    url('/server/static/fonts/AmiriQuranColored.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/AmiriQuranColored.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Santakku\";\n",
       "  src: local('Santakku'),\n",
       "    url('/server/static/fonts/Santakku.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/Santakku.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"SantakkuM\";\n",
       "  src: local('SantakkuM'),\n",
       "    url('/server/static/fonts/SantakkuM.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SantakkuM.woff?raw=true') format('woff');\n",
       "}\n",
       "/* bypassing some classical notebook settings */\n",
       "div#notebook {\n",
       "  line-height: unset;\n",
       "}\n",
       "/* neutral text */\n",
       ".txtn,.txtn a:visited,.txtn a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* transcription text */\n",
       ".txtt,.txtt a:visited,.txtt a:link {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* source text */\n",
       ".txto,.txto a:visited,.txto a:link {\n",
       "    font-family: serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* phonetic text */\n",
       ".txtp,.txtp a:visited,.txtp a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* original script text */\n",
       ".txtu,.txtu a:visited,.txtu a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* hebrew */\n",
       ".txtu.hbo,.lex.hbo {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* syriac */\n",
       ".txtu.syc,.lex.syc {\n",
       "    font-family: \"Estrangelo Edessa\", sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* neo aramaic */\n",
       ".txtu.cld,.lex.cld {\n",
       "    font-family: \"CharisSIL-R\", sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* standard arabic */\n",
       ".txtu.ara,.lex.ara {\n",
       "    font-family: \"AmiriQuran\", sans-serif;\n",
       "    font-size: large;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* cuneiform */\n",
       ".txtu.akk,.lex.akk {\n",
       "    font-family: Santakku, sans-serif;\n",
       "    font-size: large;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* greek */\n",
       ".txtu.grc,.lex.grc a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "a:hover {\n",
       "    text-decoration: underline | important;\n",
       "    color: #0000ff | important;\n",
       "}\n",
       ".ltr {\n",
       "    direction: ltr ! important;\n",
       "}\n",
       ".rtl {\n",
       "    direction: rtl ! important;\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: var(--features);\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    padding: 0.1rem;\n",
       "    margin: 0.1rem;\n",
       "    direction: ltr;\n",
       "    border: var(--meta-width) solid var(--meta-color);\n",
       "    border-radius: var(--meta-width);\n",
       "}\n",
       ".features div,.features span {\n",
       "    padding: 0;\n",
       "    margin: -0.1rem 0;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".features .xft {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: medium;\n",
       "  margin: 0.1rem 0rem;\n",
       "}\n",
       ".features .xft .f {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: small;\n",
       "  font-weight: normal;\n",
       "}\n",
       ".section {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: var(--section);\n",
       "    unicode-bidi: embed;\n",
       "    text-align: start;\n",
       "}\n",
       ".structure {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: var(--structure);\n",
       "    unicode-bidi: embed;\n",
       "    text-align: start;\n",
       "}\n",
       ".comments {\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".nd, a:link.nd {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    color: var(--node);\n",
       "    vertical-align: super;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".lex {\n",
       "  color: var(--lex-color);;\n",
       "}\n",
       ".children,.children.ltr {\n",
       "    display: flex;\n",
       "    border: 0;\n",
       "    background-color: #ffffff;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "}\n",
       ".children.stretch {\n",
       "    align-items: stretch;\n",
       "}\n",
       ".children.hor {\n",
       "    flex-flow: row nowrap;\n",
       "}\n",
       ".children.hor.wrap {\n",
       "    flex-flow: row wrap;\n",
       "}\n",
       ".children.ver {\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".children.ver.wrap {\n",
       "    flex-flow: column wrap;\n",
       "}\n",
       ".contnr {\n",
       "    width: fit-content;\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: column nowrap;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding:  0.5rem 0.1rem 0.1rem 0.1rem;\n",
       "    margin: 0.8rem 0.1rem 0.1rem 0.1rem;\n",
       "    border-style: solid;\n",
       "    font-size: small;\n",
       "}\n",
       ".contnr.trm {\n",
       "    background-attachment: local;\n",
       "}\n",
       ".contnr.cnul {\n",
       "    padding:  0;\n",
       "    margin: 0;\n",
       "    border-style: solid;\n",
       "    font-size: xx-small;\n",
       "}\n",
       ".contnr.cnul,.lbl.cnul {\n",
       "    border-color: var(--border-color-nul);\n",
       "    border-width: var(--border-width-nul);\n",
       "    border-radius: var(--border-width-nul);\n",
       "}\n",
       ".contnr.c0,.lbl.c0 {\n",
       "    border-color: var(--border-color0);\n",
       "    border-width: var(--border-width0);\n",
       "    border-radius: var(--border-width0);\n",
       "}\n",
       ".contnr.c1,.lbl.c1 {\n",
       "    border-color: var(--border-color1);\n",
       "    border-width: var(--border-width1);\n",
       "    border-radius: var(--border-width1);\n",
       "}\n",
       ".contnr.c2,.lbl.c2 {\n",
       "    border-color: var(--border-color2);\n",
       "    border-width: var(--border-width2);\n",
       "    border-radius: var(--border-width2);\n",
       "}\n",
       ".contnr.c3,.lbl.c3 {\n",
       "    border-color: var(--border-color3);\n",
       "    border-width: var(--border-width3);\n",
       "    border-radius: var(--border-width3);\n",
       "}\n",
       ".contnr.c4,.lbl.c4 {\n",
       "    border-color: var(--border-color4);\n",
       "    border-width: var(--border-width4);\n",
       "    border-radius: var(--border-width4);\n",
       "}\n",
       "span.plain {\n",
       "    display: inline-block;\n",
       "    white-space: pre-wrap;\n",
       "}\n",
       ".plain {\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".plain.l,.contnr.l,.contnr.l>.lbl {\n",
       "    border-left-style: dotted\n",
       "}\n",
       ".plain.r,.contnr.r,.contnr.r>.lbl {\n",
       "    border-right-style: dotted\n",
       "}\n",
       ".plain.lno,.contnr.lno,.contnr.lno>.lbl {\n",
       "    border-left-style: none\n",
       "}\n",
       ".plain.rno,.contnr.rno,.contnr.rno>.lbl {\n",
       "    border-right-style: none\n",
       "}\n",
       ".plain.l {\n",
       "    padding-left: 0.2rem;\n",
       "    margin-left: 0.1rem;\n",
       "    border-width: var(--border-width-plain);\n",
       "}\n",
       ".plain.r {\n",
       "    padding-right: 0.2rem;\n",
       "    margin-right: 0.1rem;\n",
       "    border-width: var(--border-width-plain);\n",
       "}\n",
       ".lbl {\n",
       "    font-family: monospace;\n",
       "    margin-top: -1.2rem;\n",
       "    margin-left: 1rem;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding: 0 0.3rem;\n",
       "    border-style: solid;\n",
       "    display: block;\n",
       "    color: var(--label)\n",
       "}\n",
       ".lbl.trm {\n",
       "    background-attachment: local;\n",
       "    margin-top: 0.1rem;\n",
       "    margin-left: 0.1rem;\n",
       "    padding: 0.1rem 0.1rem;\n",
       "    border-style: none;\n",
       "}\n",
       ".lbl.cnul {\n",
       "    font-size: xx-small;\n",
       "}\n",
       ".lbl.c0 {\n",
       "    font-size: small;\n",
       "}\n",
       ".lbl.c1 {\n",
       "    font-size: small;\n",
       "}\n",
       ".lbl.c2 {\n",
       "    font-size: medium;\n",
       "}\n",
       ".lbl.c3 {\n",
       "    font-size: medium;\n",
       "}\n",
       ".lbl.c4 {\n",
       "    font-size: large;\n",
       "}\n",
       ".occs, a:link.occs {\n",
       "    font-size: small;\n",
       "}\n",
       "\n",
       "/* PROVENANCE */\n",
       "\n",
       "div.prov {\n",
       "\tmargin: 2rem;\n",
       "\tpadding: 1rem;\n",
       "\tborder: 0.1rem solid var(--fog-rim);\n",
       "}\n",
       "div.pline {\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "}\n",
       "div.p2line {\n",
       "\tmargin-left: 2em;\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "}\n",
       "div.psline {\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "\tbackground-color: var(--gold-mist-back);\n",
       "}\n",
       "div.pname {\n",
       "\tflex: 0 0 5rem;\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.pval {\n",
       "    flex: 1 1 auto;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--node:               hsla(120, 100%,  20%, 1.0  );\n",
       "\t--label:              hsla(  0, 100%,  20%, 1.0  );\n",
       "\t--section:            hsla(  0, 100%,  25%, 1.0  );\n",
       "\t--structure:          hsla(120, 100%,  25%, 1.0  );\n",
       "\t--features:           hsla(  0,   0%,  30%, 1.0  );\n",
       "  --text-color:         hsla( 60,  80%,  10%, 1.0  );\n",
       "  --lex-color:          hsla(220,  90%,  60%, 1.0  );\n",
       "  --meta-color:         hsla(  0,   0%,  90%, 0.7  );\n",
       "  --meta-width:         0.15rem;\n",
       "  --border-color-nul:   hsla(  0,   0%,  90%, 0.5  );\n",
       "  --border-color0:      hsla(  0,   0%,  90%, 0.9  );\n",
       "  --border-color1:      hsla(  0,   0%,  80%, 0.9  );\n",
       "  --border-color2:      hsla(  0,   0%,  70%, 0.9  );\n",
       "  --border-color3:      hsla(  0,   0%,  80%, 0.8  );\n",
       "  --border-color4:      hsla(  0,   0%,  60%, 0.9  );\n",
       "  --border-width-nul:   0.1rem;\n",
       "  --border-width0:      0.1rem;\n",
       "  --border-width1:      0.15rem;\n",
       "  --border-width2:      0.2rem;\n",
       "  --border-width3:      0.3rem;\n",
       "  --border-width4:      0.25rem;\n",
       "  --border-width-plain: 0.1rem;\n",
       "}\n",
       ".hl {\n",
       "  background-color: var(--hl-strong);\n",
       "}\n",
       "span.hl {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder-width: 0;\n",
       "\tborder-radius: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "}\n",
       "div.contnr.hl,div.lbl.hl {\n",
       "  background-color: var(--hl-strong);\n",
       "}\n",
       "div.contnr.hl {\n",
       "  border-color: var(--hl-rim) ! important;\n",
       "\tborder-width: 0.2rem ! important;\n",
       "}\n",
       "\n",
       "span.hlbx {\n",
       "\tborder-color: var(--hl-rim);\n",
       "\tborder-width: 0.2rem ! important;\n",
       "\tborder-style: solid;\n",
       "\tborder-radius: 0.3rem;\n",
       "  padding: 0.2rem;\n",
       "  margin: 0.2rem;\n",
       "}\n",
       "\n",
       "span.plain {\n",
       "  display: inline-block;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--hl-strong:        hsla( 60, 100%,  70%, 0.9  );\n",
       "\t--hl-rim:           hsla( 55,  80%,  50%, 1.0  );\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Text-Fabric API:</b> names <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/cheatsheet.html\" title=\"doc\">N F E L T S C TF</a> directly usable</div><hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = use('bhsa', version=VERSION, hoist=globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load consonantal feature\n",
    "\n",
    "`g_cons` is the consonantal representation of a word occurrence in BHSA transliteration. It operates on a word object. The feature is needed for the conversion of the annotation of suffixes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "  0.02s All additional features loaded - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "TF.load('g_cons', add=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Chapters for TF Conversion\n",
    "\n",
    "When a certain part of the desired annotations have been done, but not everything yet, it is possible to select a specific number of chapters for the conversion. Just uncomment line 1 in the cell below, and comment line 3. If you want to convert all annotations, just run the cell as it is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selectChapters = {42} #Isaiah: 42, Genesis: 1\n",
    "\n",
    "selectChapters = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Features for TF\n",
    "\n",
    "Three features are made:\n",
    "\n",
    "1. `mention`: contains all referring expressions which consist of NP's, named entities, suffixes, person/gender/number of verbs, personal pronouns and demonstrative pronouns, . \n",
    "2. `mentionNote`: annotator notes that have been stored on the mentions. \n",
    "3. `coref`: the coreference relations between mentions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeFeatures = dict(\n",
    "    mention={},\n",
    "    mentionNote={},\n",
    "    coref={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookupNode(aStart, standoffInfo, standoffInfoNonFirst):\n",
    "    node = None\n",
    "    isPart = False\n",
    "    if aStart in standoffInfo:\n",
    "        (node, sEnd, sWord) = standoffInfo[aStart]\n",
    "    else:\n",
    "        if aStart in standoffInfoNonFirst:\n",
    "            (node, sEnd, sWord) = standoffInfo[standoffInfoNonFirst[aStart]]\n",
    "            isPart = aStart != sEnd\n",
    "    return (node, isPart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get All Features With Standard TF Data Enrichment\n",
    "\n",
    "Specify the Hebrew Bible book that has been annotated in `getFeatures()` below. `getFeatures` assembles all the features that are necessary for a sound TF conversion. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def getFeatures(bookName):\n",
    "    bookBase = f'{OUTPUT_BASE}/{bookName}'\n",
    "    files = glob(f'{bookBase}/{ANNOTATE}/*.ann')\n",
    "    \n",
    "    nChapters = 0\n",
    "    \n",
    "    for annFile in sorted(files):\n",
    "        (directory, fileNameFull) = os.path.split(annFile)\n",
    "        (fileName, ext) = os.path.splitext(fileNameFull)\n",
    "        standoffFile = f'{bookBase}/{STANDOFF}/{fileName}.tsv'\n",
    "        chapter = int(fileName[len(bookName) + 1:].lstrip('0'))\n",
    "        if selectChapters is not None and chapter not in selectChapters:\n",
    "            continue\n",
    "        \n",
    "        standoffInfo = {}\n",
    "        standoffInfoNonFirst = {}\n",
    "        \n",
    "        with open(standoffFile) as fh:\n",
    "            first = True\n",
    "            errors = 0\n",
    "            minPos = None\n",
    "            maxPos = None\n",
    "            for (i, line) in enumerate(fh):\n",
    "                epos = f'{fileName}.tsv{i + 1} - '\n",
    "                if first:\n",
    "                    first = False\n",
    "                    continue  # header\n",
    "                (start, end, node, word) = line.rstrip('\\n').split('\\t')\n",
    "                start = int(start)\n",
    "                end = int(end)\n",
    "                node = int(node)\n",
    "                if start == end:  # empty word\n",
    "                    continue\n",
    "                if maxPos is None or end > maxPos:\n",
    "                    maxPos = end\n",
    "                if minPos is None or start < minPos:\n",
    "                    minPos = start\n",
    "                if start in standoffInfo:\n",
    "                    error(f'{epos}{start} for multiple items: {standoffInfo[start]}')\n",
    "                    errors += 1\n",
    "                standoffInfo[start] = (node, end, word)\n",
    "        \n",
    "        currentStart = None\n",
    "        \n",
    "        for p in range(minPos, maxPos + 1):\n",
    "            if p in standoffInfo:\n",
    "                currentStart = p\n",
    "            else:\n",
    "                standoffInfoNonFirst[p] = currentStart\n",
    "        \n",
    "        if errors:\n",
    "            error(f'{book} {chapter}: {errors} errors in standoff file')\n",
    "        \n",
    "        errors = 0\n",
    "        \n",
    "        mention = {}\n",
    "        mentionNote = {}\n",
    "        coref = {}\n",
    "        \n",
    "        firstChars = {'T', '#', '*'}\n",
    "        cClass = 0\n",
    "        \n",
    "        with open(annFile) as fh:\n",
    "            for (i, line) in enumerate(fh):\n",
    "                epos = f'{fileName}.tsv:{i + 1} - '\n",
    "                line = line.rstrip('\\n')\n",
    "                firstChar = line[0]\n",
    "                \n",
    "                if firstChar not in firstChars:\n",
    "                    error(f'{epos}Unrecognized line \"{line}\"')\n",
    "                    errors +=1\n",
    "                    continue\n",
    "                    \n",
    "                numFields = 2 if firstChar =='*' else 3\n",
    "                parts = line.split('\\t')\n",
    "                \n",
    "                if len(parts) != numFields:\n",
    "                    error(f'{epos}line does not have exactly {numFields} parts: \"{line}\"')\n",
    "                    errors += 1\n",
    "                    continue\n",
    "                        \n",
    "                if firstChar == 'T':\n",
    "                    (tPart, mentionStr, aWord) = parts\n",
    "                    mParts = mentionStr.split()\n",
    "                    if len(mParts) != 3:\n",
    "                        error(f'{epos}T-line mention does not have exactly 3 parts: \"{line}\"')\n",
    "                        errors += 1\n",
    "                        continue\n",
    "                    (mm, aStart, aEnd) = mParts\n",
    "                    aStart = int(aStart)\n",
    "                    aEnd = int(aEnd)\n",
    "                    \n",
    "                    (nodeStart, isPartStart) = lookupNode(aStart, standoffInfo, standoffInfoNonFirst)\n",
    "                    if nodeStart is None:\n",
    "                        error(f'{epos}Mention start position not found in standoff file \"{line}\"')\n",
    "                        errors += 1\n",
    "                        continue\n",
    "\n",
    "                    (nodeEnd, isPartEnd) = lookupNode(aEnd, standoffInfo, standoffInfoNonFirst)\n",
    "                    if nodeEnd is None:\n",
    "                        error(f'{epos}Mention end position not found in standoff file \"{line}\"')\n",
    "                        errors += 1\n",
    "                        continue\n",
    "                    wordSize = nodeEnd - nodeStart + 1\n",
    "                    wordPart = aWord if isPartStart or isPartEnd else None\n",
    "                            \n",
    "                    mention.setdefault(nodeStart, []).append((tPart, wordSize, wordPart))\n",
    "                        \n",
    "                elif firstChar == '#':\n",
    "                    (code, spec, note) = parts\n",
    "                    sParts = spec.split()\n",
    "                    if len(sParts) != 2:\n",
    "                        error(f'{epos}#-line spec does not have exactly 2 parts: \"{line}\"')\n",
    "                        errors += 1\n",
    "                        continue\n",
    "                    tPart = sParts[1]\n",
    "                    mentionNote.setdefault(tPart, set()).add(note)\n",
    "                elif firstChar == '*':\n",
    "                    (char, data) = parts\n",
    "                    dataParts = data.split()\n",
    "                    if len(dataParts) <= 1 or dataParts[0] != 'Coreference':\n",
    "                        error(f'{epos}*-line spec does not have the right parts: \"{line}\"')\n",
    "                        errors += 1\n",
    "                        continue\n",
    "                    cClass += 1\n",
    "                    for tPart in dataParts[1:]:\n",
    "                        if tPart in coref:\n",
    "                            error(f'{epos}*-\"{tPart} occurs in multiple classes \"{coref[tPart]}\" in \"{line}\"')\n",
    "                            errors += 1\n",
    "                            continue\n",
    "                        coref[tPart] = f'C{cClass}'\n",
    "                    \n",
    "        if errors:\n",
    "            error(f'{book} {chapter}: {errors} errors in annotation file')\n",
    "        else:\n",
    "            info('.', tm=False, nl=False)\n",
    "        \n",
    "        for (node, parts) in mention.items():\n",
    "            parts = sorted(\n",
    "                (x for x in parts),\n",
    "                key=lambda x: ('' if x[2] is None else x[2], x[1], x[0])\n",
    "            )\n",
    "            valuesM = []\n",
    "            valuesC = []\n",
    "            notes = set()\n",
    "\n",
    "            for (tPart, wordSize, wordPart) in parts:\n",
    "                cPart = coref.get(tPart, tPart)\n",
    "\n",
    "                wordSize = str(wordSize) if wordSize > 1 else ''\n",
    "                wordPart = wordPart or ''\n",
    "\n",
    "                isSuffix = 's' if wordPart and F.g_cons.v(node).endswith(wordPart) else ''\n",
    "                \n",
    "                valueM = (tPart[0], tPart[1:], wordSize, isSuffix, wordPart)\n",
    "                valueC = (cPart[0], cPart[1:], wordSize, isSuffix, wordPart)\n",
    "                \n",
    "                valuesM.append(','.join(valueM))\n",
    "                valuesC.append(','.join(valueC))\n",
    "                \n",
    "                if tPart in mentionNote:\n",
    "                    notes |= mentionNote[tPart]\n",
    "                         \n",
    "            nodeFeatures['mention'][node] = '|'.join(valuesM)            \n",
    "            nodeFeatures['coref'][node] = '|'.join(valuesC)\n",
    "            if notes:\n",
    "                nodeFeatures['mentionNote'][node] = '|'.join(sorted(notes))\n",
    "                \n",
    "        nChapters += 1\n",
    "                \n",
    "    info('', tm=False)\n",
    "    info(f'Done assembling features of {nChapters} chapters')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "getFeatures('Genesis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get All Features With TF Data Enrichment and Full Annotations\n",
    "\n",
    "Specify the Hebrew Bible book that has been annotated in `getFullFeatures()` below. `getFullFeatures` assembles all the features that are necessary for a sound TF conversion plus all annotations that have been made in brat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFullFeatures(bookName):\n",
    "    bookBase = f'{OUTPUT_BASE}/{bookName}'\n",
    "    files = glob(f'{bookBase}/{ANNOTATE}/*.ann')\n",
    "    \n",
    "    nChapters = 0\n",
    "    \n",
    "    for annFile in sorted(files):\n",
    "        (directory, fileNameFull) = os.path.split(annFile)\n",
    "        (fileName, ext) = os.path.splitext(fileNameFull)\n",
    "        standoffFile = f'{bookBase}/{STANDOFF}/{fileName}.tsv'\n",
    "        chapter = int(fileName[len(bookName) + 1:].lstrip('0'))\n",
    "        if selectChapters is not None and chapter not in selectChapters:\n",
    "            continue\n",
    "        \n",
    "        standoffInfo = {}\n",
    "        standoffInfoNonFirst = {}\n",
    "        \n",
    "        with open(standoffFile) as fh:\n",
    "            first = True\n",
    "            errors = 0\n",
    "            minPos = None\n",
    "            maxPos = None\n",
    "            for (i, line) in enumerate(fh):\n",
    "                epos = f'{fileName}.tsv{i + 1} - '\n",
    "                if first:\n",
    "                    first = False\n",
    "                    continue  # header\n",
    "                (start, end, node, word) = line.rstrip('\\n').split('\\t')\n",
    "                start = int(start)\n",
    "                end = int(end)\n",
    "                node = int(node)\n",
    "                if start == end:  # empty word\n",
    "                    continue\n",
    "                if maxPos is None or end > maxPos:\n",
    "                    maxPos = end\n",
    "                if minPos is None or start < minPos:\n",
    "                    minPos = start\n",
    "                if start in standoffInfo:\n",
    "                    error(f'{epos}{start} for multiple items: {standoffInfo[start]}')\n",
    "                    errors += 1\n",
    "                standoffInfo[start] = (node, end, word)\n",
    "        \n",
    "        currentStart = None\n",
    "        \n",
    "        for p in range(minPos, maxPos + 1):\n",
    "            if p in standoffInfo:\n",
    "                currentStart = p\n",
    "            else:\n",
    "                standoffInfoNonFirst[p] = currentStart\n",
    "        \n",
    "        if errors:\n",
    "            error(f'{book} {chapter}: {errors} errors in standoff file')\n",
    "        \n",
    "        errors = 0\n",
    "        \n",
    "        mention = {}\n",
    "        mentionNote = {}\n",
    "        coref = {}\n",
    "        \n",
    "        firstChars = {'T', '#', '*'}\n",
    "        cClass = 0\n",
    "        \n",
    "        with open(annFile) as fh:\n",
    "            for (i, line) in enumerate(fh):\n",
    "                epos = f'{fileName}.tsv:{i + 1} - '\n",
    "                line = line.rstrip('\\n')\n",
    "                firstChar = line[0]\n",
    "                \n",
    "                if firstChar not in firstChars:\n",
    "                    error(f'{epos}Unrecognized line \"{line}\"')\n",
    "                    errors +=1\n",
    "                    continue\n",
    "                    \n",
    "                numFields = 2 if firstChar =='*' else 3\n",
    "                parts = line.split('\\t')\n",
    "                \n",
    "                if len(parts) != numFields:\n",
    "                    error(f'{epos}line does not have exactly {numFields} parts: \"{line}\"')\n",
    "                    errors += 1\n",
    "                    continue\n",
    "                        \n",
    "                if firstChar == 'T':\n",
    "                    (tPart, mentionStr, aWord) = parts\n",
    "                    mParts = mentionStr.split()\n",
    "                    if len(mParts) != 3:\n",
    "                        error(f'{epos}T-line mention does not have exactly 3 parts: \"{line}\"')\n",
    "                        errors += 1\n",
    "                        continue\n",
    "                    (mm, aStart, aEnd) = mParts\n",
    "                    aStart = int(aStart)\n",
    "                    aEnd = int(aEnd)\n",
    "                    \n",
    "                    (nodeStart, isPartStart) = lookupNode(aStart, standoffInfo, standoffInfoNonFirst)\n",
    "                    if nodeStart is None:\n",
    "                        error(f'{epos}Mention start position not found in standoff file \"{line}\"')\n",
    "                        errors += 1\n",
    "                        continue\n",
    "\n",
    "                    (nodeEnd, isPartEnd) = lookupNode(aEnd, standoffInfo, standoffInfoNonFirst)\n",
    "                    if nodeEnd is None:\n",
    "                        error(f'{epos}Mention end position not found in standoff file \"{line}\"')\n",
    "                        errors += 1\n",
    "                        continue\n",
    "                    wordSize = nodeEnd - nodeStart + 1\n",
    "                    wordPart = aWord# if isPartStart or isPartEnd else None        \n",
    "                    mention.setdefault(nodeStart, []).append((tPart, wordSize, wordPart))\n",
    "                    \n",
    "                elif firstChar == '#':\n",
    "                    (code, spec, note) = parts\n",
    "                    sParts = spec.split()\n",
    "                    if len(sParts) != 2:\n",
    "                        error(f'{epos}#-line spec does not have exactly 2 parts: \"{line}\"')\n",
    "                        errors += 1\n",
    "                        continue\n",
    "                    tPart = sParts[1]\n",
    "                    mentionNote.setdefault(tPart, set()).add(f'{tPart}-{note}')\n",
    "                    #mentionNote.setdefault(tPart, set()).add(note)\n",
    "            \n",
    "                elif firstChar == '*':\n",
    "                    (char, data) = parts\n",
    "                    dataParts = data.split()\n",
    "                    if len(dataParts) <= 1 or dataParts[0] != 'Coreference':\n",
    "                        error(f'{epos}*-line spec does not have the right parts: \"{line}\"')\n",
    "                        errors += 1\n",
    "                        continue\n",
    "                    cClass += 1\n",
    "                    for tPart in dataParts[1:]:\n",
    "                        if tPart in coref:\n",
    "                            error(f'{epos}*-\"{tPart} occurs in multiple classes \"{coref[tPart]}\" in \"{line}\"')\n",
    "                            errors += 1\n",
    "                            continue\n",
    "                        coref[tPart] = f'C{cClass}'\n",
    "                   \n",
    "        if errors:\n",
    "            error(f'{book} {chapter}: {errors} errors in annotation file')\n",
    "        else:\n",
    "            A.info('.', tm=False, nl=False)\n",
    "        \n",
    "        for (node, parts) in mention.items():\n",
    "            parts = sorted(\n",
    "                (x for x in parts),\n",
    "                key=lambda x: ('' if x[2] is None else x[2], x[1], x[0])\n",
    "            )\n",
    "            valuesM = []\n",
    "            valuesC = []\n",
    "            notes = set()\n",
    "\n",
    "            for (tPart, wordSize, wordPart) in parts:\n",
    "                cPart = coref.get(tPart, tPart)\n",
    "                wordSize = str(wordSize) if wordSize > 1 else ''\n",
    "                wordPart = wordPart or ''\n",
    "                \n",
    "                isSuffix = 's' if wordPart in suffix_dict else ''\n",
    "                \n",
    "                valueM = (tPart[0], tPart[1:], wordSize, isSuffix, wordPart)\n",
    "                valueC = (cPart[0], cPart[1:], wordSize, isSuffix, wordPart)\n",
    "                \n",
    "                valuesM.append(','.join(valueM))\n",
    "                valuesC.append(','.join(valueC))\n",
    "                \n",
    "                if tPart in mentionNote:\n",
    "                    notes |= mentionNote[tPart]\n",
    "                         \n",
    "            nodeFeatures['mention'][node] = '|'.join(valuesM)            \n",
    "            nodeFeatures['coref'][node] = '|'.join(valuesC)\n",
    "            if notes:\n",
    "                nodeFeatures['mentionNote'][node] = '|'.join(sorted(notes))\n",
    "                \n",
    "        nChapters += 1\n",
    "                \n",
    "    A.info('', tm=False)\n",
    "    A.info(f'Done assembling features of {nChapters} chapters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Conversion Function `getFullFeatures()`\n",
    "\n",
    "1. Do conversion in canonical order: Genesis, Numbers (see bullet 2), Isaiah, Psalms with selectChapters = None\n",
    "2. Change OUTPUT_BASE directory for Numbers\n",
    "3. Do not rerun notebook from top when adding a new book, just rerun `getFullFeatures()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................................................................................................................................................\n",
      "13m 05s Done assembling features of 150 chapters\n"
     ]
    }
   ],
   "source": [
    "getFullFeatures('Psalms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Metadeta\n",
    "\n",
    "Before the actual conversion takes place first the metadata need to be specified below. Since I have annotated the Psalms data myself, I am the only author. Of course it is possible to specify multiple authors or annotators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaData = {\n",
    "    '': dict(\n",
    "            title='Participant analysis',\n",
    "            author='Christiaan Erwich (Psalms, Genesis 1, Isaiah 42) and Gyusang Jin (Numbers)',\n",
    "    ),\n",
    "    'mention': dict(\n",
    "        valueType='str',\n",
    "        description='mention annotations made through Brat',\n",
    "        explanation='the analysis is per chapter',\n",
    "    ),\n",
    "    'mentionNote': dict(\n",
    "        valueType='str',\n",
    "        description='comments on mention annotations made through Brat',\n",
    "        explanation='the analysis is per chapter',\n",
    "    ),\n",
    "    'coref': dict(\n",
    "        valueType='str',\n",
    "        description='coreference equivalence class of mention annotations made through Brat',\n",
    "        explanation='the analysis is per chapter',\n",
    "    ),\n",
    "}\n",
    "\n",
    "edgeFeatures = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert \n",
    "\n",
    "The new features are stored in my github repository as can be seen below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 8.3.3\n",
      "Api reference : https://annotation.github.io/text-fabric/cheatsheet.html\n",
      "\n",
      "3 features found and 0 ignored\n",
      "  0.01s Warp feature \"otype\" not found in\n",
      "~/github/cmerwich/participant-analysis/coreference/tf/2017/\n",
      "  0.01s Warp feature \"oslots\" not found in\n",
      "~/github/cmerwich/participant-analysis/coreference/tf/2017/\n",
      "  0.02s Warp feature \"otext\" not found. Working without Text-API\n",
      "\n",
      "  0.00s Exporting 3 node and 0 edge and 0 config features to ~/github/cmerwich/participant-analysis/coreference/tf/2017:\n",
      "   |     0.08s T coref                to ~/github/cmerwich/participant-analysis/coreference/tf/2017\n",
      "   |     0.07s T mention              to ~/github/cmerwich/participant-analysis/coreference/tf/2017\n",
      "   |     0.02s T mentionNote          to ~/github/cmerwich/participant-analysis/coreference/tf/2017\n",
      "  0.17s Exported 3 node features and 0 edge features and 0 config features to ~/github/cmerwich/participant-analysis/coreference/tf/2017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFW = Fabric(locations=f'{GITHUB_BASE}/{ORG}/{REPO}/{PATH}/{VERSION}')\n",
    "TFW.save(\n",
    "    nodeFeatures=nodeFeatures,\n",
    "    edgeFeatures=edgeFeatures,\n",
    "    metaData=metaData,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
