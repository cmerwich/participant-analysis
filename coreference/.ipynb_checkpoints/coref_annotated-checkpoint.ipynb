{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import standard Python stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, pickle, csv, collections\n",
    "from collections import *\n",
    "from IPython.display import HTML\n",
    "from pprint import pprint\n",
    "from functools import reduce\n",
    "\n",
    "from tf.fabric import Fabric\n",
    "from tf.transcription import Transcription\n",
    "from tf.extra.bhsa import Bhsa\n",
    "\n",
    "import numpy as np\n",
    "from pandas import DataFrame, read_csv\n",
    "import pandas as pd\n",
    "from random import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 5.4.1\n",
      "Api reference : https://dans-labs.github.io/text-fabric/Api/General/\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "119 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "VERSION = 'c'\n",
    "DATABASE = '~/github/etcbc'\n",
    "BHSA = f'bhsa/tf/{VERSION}'\n",
    "REFERENCE = f'bh-reference-system/tf/{VERSION}' # Check my GitHub to download these extra features\n",
    "TF = Fabric(locations=[DATABASE], modules=[BHSA, REFERENCE], silent=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load the necessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Documentation:** <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa\" title=\"{provenance of this corpus}\">BHSA</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/0_home.html\" title=\"{CORPUS.upper()} feature documentation\">Feature docs</a> <a target=\"_blank\" href=\"https://dans-labs.github.io/text-fabric/Api/Bhsa/\" title=\"BHSA API documentation\">BHSA API</a> <a target=\"_blank\" href=\"https://dans-labs.github.io/text-fabric/Api/General/\" title=\"text-fabric-api\">Text-Fabric API 5.4.1</a> <a target=\"_blank\" href=\"https://dans-labs.github.io/text-fabric/Api/General/#search-templates\" title=\"Search Templates Introduction and Reference\">Search Reference</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style type=\"text/css\">\n",
       ".verse {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".vl {\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-end;\n",
       "    align-items: flex-end;\n",
       "    direction: ltr;\n",
       "    width: 100%;\n",
       "}\n",
       ".outeritem {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".sentence,.clause,.phrase {\n",
       "    margin-top: -1.2em;\n",
       "    margin-left: 1em;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding: 0 0.3em;\n",
       "    border-style: solid;\n",
       "    border-radius: 0.2em;\n",
       "    font-size: small;\n",
       "    display: block;\n",
       "    width: fit-content;\n",
       "    max-width: fit-content;\n",
       "    direction: ltr;\n",
       "}\n",
       ".atoms {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    margin: 0.3em;\n",
       "    padding: 0.3em;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".satom,.catom,.patom {\n",
       "    margin: 0.3em;\n",
       "    padding: 0.3em;\n",
       "    border-radius: 0.3em;\n",
       "    border-style: solid;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".sentence {\n",
       "    border-color: #aa3333;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".clause {\n",
       "    border-color: #aaaa33;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".phrase {\n",
       "    border-color: #33aaaa;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".satom {\n",
       "    border-color: #aa3333;\n",
       "    border-width: 4px;\n",
       "}\n",
       ".catom {\n",
       "    border-color: #aaaa33;\n",
       "    border-width: 3px;\n",
       "}\n",
       ".patom {\n",
       "    border-color: #33aaaa;\n",
       "    border-width: 3px;\n",
       "}\n",
       ".word {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 1px solid #cccccc;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".lex {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 2px solid #888888;\n",
       "    width: fit-content;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".occs {\n",
       "    font-size: x-small;\n",
       "}\n",
       ".satom.l,.catom.l,.patom.l {\n",
       "    border-left-style: dotted\n",
       "}\n",
       ".satom.r,.catom.r,.patom.r {\n",
       "    border-right-style: dotted\n",
       "}\n",
       ".satom.L,.catom.L,.patom.L {\n",
       "    border-left-style: none\n",
       "}\n",
       ".satom.R,.catom.R,.patom.R {\n",
       "    border-right-style: none\n",
       "}\n",
       ".h,.h a:visited,.h a:link {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".hb,.hb a:visited,.hb a:link {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".rela,.function,.typ {\n",
       "    font-family: monospace;\n",
       "    font-size: small;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".pdp,.pdp a:visited,.pdp a:link {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".voc_lex {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vs {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vt {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".gloss {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: normal;\n",
       "    color: #aaaaaa;\n",
       "}\n",
       ".vrs {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: #444444;\n",
       "}\n",
       ".nd {\n",
       "    font-family: monospace;\n",
       "    font-size: x-small;\n",
       "    color: #999999;\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0a6611;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: x-small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".word .features div,.word .features span {\n",
       "    padding: 0;\n",
       "    margin: -0.1rem 0;\n",
       "}\n",
       "\n",
       ".hl {\n",
       "    background-color: #ffee66;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "api = TF.load('''\n",
    "    otype\n",
    "    lex book chapter verse\n",
    "    nu ps gn prs ls lex gloss\n",
    "    function sp typ pdp language \n",
    "    pgn_prps pgn_prde pgn_verb \n",
    "    pgn_verb_prs pgn_prs\n",
    "''', silent=True)\n",
    "\n",
    "api.makeAvailableIn(globals())\n",
    "\n",
    "B = Bhsa(api, 'coref annotated', version=VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Retrieve data from Text-Fabric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MY_BOOK = {'Psalms'} # Set any Hebrew Bible Book\n",
    "MY_CHAPTERS = set(range(1,6)) # Set any range in 150 chapters of the Psalms\n",
    "\n",
    "words_list = []\n",
    "coref_info_dict = {}\n",
    "\n",
    "def get_coref_info():\n",
    "    \n",
    "    '''Function retrieves all information needed for coreference resolution.\n",
    "    The data = wordnode, indexnumber, book, chap, verse, hbtext, gloss, pgn, pdp, typ, ls\n",
    "    '''\n",
    "    \n",
    "    for book in F.otype.s('book'):\n",
    "        book_name = T.bookName(book)\n",
    "        \n",
    "        for chn in L.d(book, 'chapter'):\n",
    "            chapter = F.chapter.v(chn)\n",
    "            \n",
    "            if book_name in MY_BOOK and chapter in MY_CHAPTERS:\n",
    "                \n",
    "                for vn in L.d(chn, 'verse'):\n",
    "                    verse_list = [] # make one list per verse: contains all words in one verse\n",
    "                    \n",
    "                    for phrn in L.d(vn, 'phrase'):\n",
    "                        \n",
    "                        for word in L.d(phrn, 'word'): \n",
    "                            \n",
    "                            verse_list.append(word)\n",
    "                            words_list.append(word)\n",
    "                        \n",
    "                            for i, w in enumerate(verse_list): #index all words in one verse, start = 0\n",
    "                                \n",
    "                                boo, chap, vers = T.sectionFromNode(w)\n",
    "                                hbtext = T.text([w], fmt='text-orig-plain')\n",
    "                                info = [w, i, boo, chap, vers, hbtext] # add all info that needs no checking/reworking\n",
    "                                \n",
    "                                lex = L.u(w, 'lex')[0]\n",
    "                                # replace multiple glosses for one word with ',' and space by a '-'\n",
    "                                gloss = F.gloss.v(lex).replace(', ','-') \n",
    "                                info.append(gloss)\n",
    "                                \n",
    "                                pgn_prps = F.pgn_prps.v(w)\n",
    "                                pgn_prde = F.pgn_prde.v(w)\n",
    "                                pgn_verb = F.pgn_verb.v(w)\n",
    "                                pgn_prs = F.pgn_prs.v(w)\n",
    "                                pgn_verb_prs = F.pgn_verb_prs.v(w)\n",
    "                                \n",
    "                                if pgn_prps:\n",
    "                                    info.append(pgn_prps)\n",
    "                                elif pgn_prde:\n",
    "                                    info.append(pgn_prde)\n",
    "                                elif pgn_verb and pgn_prs:\n",
    "                                    info.append(pgn_verb_prs)\n",
    "                                elif pgn_verb and not pgn_prs:\n",
    "                                    info.append(pgn_verb)\n",
    "                                elif pgn_prs and not pgn_verb:\n",
    "                                    info.append(pgn_prs)\n",
    "                                else:\n",
    "                                    info.append('-')\n",
    "                                \n",
    "                                pdp = F.pdp.v(w)\n",
    "                                info.append(pdp)\n",
    "                                \n",
    "                                phrase = L.u(w, 'phrase')[0]\n",
    "                                typ = F.typ.v(phrase)\n",
    "                                info.append(typ)\n",
    "            \n",
    "                                ls = F.ls.v(w)\n",
    "                                if ls == 'none':\n",
    "                                    info.append('-')\n",
    "                                else:\n",
    "                                    info.append(ls)\n",
    "                            \n",
    "                                coref_info_dict[w] = info \n",
    "\n",
    "    return words_list, coref_info_dict\n",
    "                               \n",
    "#get_coref_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Make dataset - Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list, coref_info_dict = get_coref_info() \n",
    "\n",
    "with open('coref_to_annotate_wouter.csv', 'w') as f:\n",
    "    header = ['wordnode', 'index', 'book', 'chapter', 'verse', 'hbword', 'gloss', 'pgn', 'pdp_pos', 'phrase_type', 'lexical_set', 'coref']\n",
    "    f.write('{}\\n'.format(','.join(header)))\n",
    "    \n",
    "    for node in words_list:\n",
    "        info_list = coref_info_dict[node]\n",
    "        line = [str(element) for element in info_list]\n",
    "        f.write('{}\\n'.format(','.join(line)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
